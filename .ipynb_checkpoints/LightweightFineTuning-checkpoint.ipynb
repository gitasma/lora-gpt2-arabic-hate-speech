{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f35354cd",
   "metadata": {},
   "source": [
    "# Lightweight Fine-Tuning Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560fb3ff",
   "metadata": {},
   "source": [
    "TODO: In this cell, describe your choices for each of the following\n",
    "\n",
    "* PEFT technique: \n",
    "* Model: \n",
    "* Evaluation approach: \n",
    "* Fine-tuning dataset: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8d76bb",
   "metadata": {},
   "source": [
    "## Loading and Evaluating a Foundation Model\n",
    "\n",
    "TODO: In the cells below, load your chosen pre-trained Hugging Face model and evaluate its performance prior to fine-tuning. This step includes loading an appropriate tokenizer and dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f551c63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from peft import AutoPeftModelForSequenceClassification\n",
    "from transformers import DataCollatorWithPadding, Trainer, TrainingArguments\n",
    "from transformers import BitsAndBytesConfig\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "from peft import LoraConfig, get_peft_model\n",
    "import torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4935cb4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "702ffb66c02e49ba8bccc5443e2cd5de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 420k/420k [00:00<00:00, 2.11MB/s]\n",
      "Downloading data: 100%|██████████| 108k/108k [00:00<00:00, 1.43MB/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25a5f05c4f774f5899460d99768c69ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/6535 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36112dca58d14e7eb53f59dfc14009a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1634 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 6535\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 1634\n",
      "    })\n",
      "})\n",
      "{0: 'Religious Discrimination', 1: 'Offensive', 2: 'Racism', 3: 'Neutral', 4: 'Sexism'}\n",
      "{'Religious Discrimination': 0, 'Offensive': 1, 'Racism': 2, 'Neutral': 3, 'Sexism': 4}\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"IbrahimAmin/egyptian-arabic-hate-speech\")\n",
    "for split in ['train', 'test']:\n",
    "    dataset[split].shuffle(seed=42)\n",
    "print(dataset)\n",
    "id2label   = { i: name for i, name in enumerate(set(dataset['test']['label'])) }\n",
    "label2id   = { name: i for i, name in enumerate(set(dataset['test']['label'])) }\n",
    "print(id2label)\n",
    "print(label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe017682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels information\n",
      "Number of classes - train: 5\n",
      "Number of classes - test : 5\n",
      "Labels - train: {'Religious Discrimination', 'Offensive', 'Racism', 'Neutral', 'Sexism'}\n",
      "Labels - test : {'Religious Discrimination', 'Offensive', 'Racism', 'Neutral', 'Sexism'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Labels information\")\n",
    "num_labels = len(set(dataset['train']['label']))\n",
    "print(f\"Number of classes - train: {num_labels}\")\n",
    "num_labels = len(set(dataset['test']['label']))\n",
    "print(f\"Number of classes - test : {num_labels}\")\n",
    "print(f\"Labels - train: {set(dataset['train']['label'])}\")\n",
    "print(f\"Labels - test : {set(dataset['test']['label'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b25afe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "284f7f63de6f4c1580afc0ec09daf25a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3571fc774d8a4720b4244a0b84b0a5ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f9f92985ee947b980934184e77cbc72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eebdab1f7b9407eb5b9ddd8b793d8ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88bbe98019c846bb90e6cfdfcf302c02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecd72eeb7539414686e76d0d5473a12a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"gpt2\",\n",
    "    num_labels=num_labels,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "base_model.config.pad_token_id = tokenizer.eos_token_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bde3cb2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2ForSequenceClassification(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (score): Linear(in_features=768, out_features=5, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfbfe750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight: Parameter containing:\n",
      "tensor([[ 0.0031,  0.0055,  0.0034,  ...,  0.0051, -0.0155, -0.0438],\n",
      "        [ 0.0113,  0.0241, -0.0040,  ...,  0.0078, -0.0217, -0.0076],\n",
      "        [-0.0054, -0.0023, -0.0147,  ...,  0.0127,  0.0315, -0.0270],\n",
      "        [-0.0137,  0.0243, -0.0260,  ..., -0.0130,  0.0027,  0.0454],\n",
      "        [ 0.0168,  0.0175, -0.0219,  ..., -0.0233, -0.0272,  0.0018]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "head = base_model.score\n",
    "for n, p in head.named_parameters():\n",
    "    print(f\"{n}: {p}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fa09830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4bb774b2e474183b544c3fe71aafd2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6535 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64bcd60cef984463bf7aec2d83d371b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1634 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b058682b70f40d586fa74b748dc1dab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6535 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef181f3aa6b64e7280228af097ab4f37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1634 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def add_label_id(example):\n",
    "    example[\"label_id\"] = label2id[example[\"label\"]]\n",
    "    return example\n",
    "\n",
    "def tokenize_and_attach_id(example):\n",
    "    tokenized = tokenizer(\n",
    "        example[\"text\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    tokenized[\"labels\"] = example[\"label_id\"]\n",
    "    return tokenized\n",
    "\n",
    "dataset = dataset.map(add_label_id)\n",
    "tokenized_dataset = {}\n",
    "for split in ['train', 'test']:\n",
    "    tokenized_dataset[split] = dataset[split].map(tokenize_and_attach_id,\n",
    "                                                  batched=True,\n",
    "                                                  remove_columns=dataset[split].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cefdd12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "البنات مش نافعين لا في كوره ولا في السياسه ولا في شغل ولا في أي حاجه خالص\n",
      "\n",
      "[23525, 39848, 23338, 34247, 103, 47048, 148, 112, 18923, 228, 12919, 149, 223, 44690, 22654, 23338, 220, 13862, 12919, 18923, 223, 22654, 18923, 225, 30335, 26897, 29519, 42092, 13862, 12919, 18923, 223, 22654, 28981, 45692, 22654, 34247, 111, 29519, 42092, 13862, 12919, 18923, 223, 22654, 17550, 112, 148, 118, 13862, 42092, 13862, 12919, 18923, 223, 22654, 17550, 96, 22654, 17550, 255, 34247, 105, 29519, 17550, 106, 23525, 148, 113, 50256]\n",
      "\n",
      "['Ø§ÙĦ', 'Ø¨', 'ÙĨ', 'Ø§Ø', 'ª', 'ĠÙħ', 'Ø', '´', 'ĠÙ', 'Ĩ', 'Ø§', 'Ù', 'ģ', 'Ø¹', 'ÙĬ', 'ÙĨ', 'Ġ', 'ÙĦ', 'Ø§', 'ĠÙ', 'ģ', 'ÙĬ', 'ĠÙ', 'ĥ', 'ÙĪ', 'Ø±', 'Ùĩ', 'ĠÙĪ', 'ÙĦ', 'Ø§', 'ĠÙ', 'ģ', 'ÙĬ', 'ĠØ§ÙĦ', 'Ø³', 'ÙĬ', 'Ø§Ø', '³', 'Ùĩ', 'ĠÙĪ', 'ÙĦ', 'Ø§', 'ĠÙ', 'ģ', 'ÙĬ', 'ĠØ', '´', 'Ø', 'º', 'ÙĦ', 'ĠÙĪ', 'ÙĦ', 'Ø§', 'ĠÙ', 'ģ', 'ÙĬ', 'ĠØ', '£', 'ÙĬ', 'ĠØ', 'Ń', 'Ø§Ø', '¬', 'Ùĩ', 'ĠØ', '®', 'Ø§ÙĦ', 'Ø', 'µ', '<|endoftext|>']\n",
      "\n",
      "البنات مش نافعين لا في كوره ولا في السياسه ولا في شغل ولا في أي حاجه خالص\n"
     ]
    }
   ],
   "source": [
    "sample = dataset[\"train\"][3445]\n",
    "print(f\"{dataset['train'][3445]['text']}\\n\")\n",
    "tokenized_sample = tokenized_dataset[\"train\"][3445][\"input_ids\"]\n",
    "print(f\"{tokenized_sample[0:70]}\\n\")\n",
    "if hasattr(tokenized_sample, \"tolist\"):\n",
    "    tokenized_sample = tokenized_sample.tolist()\n",
    "tokens = tokenizer.convert_ids_to_tokens(tokenized_sample)\n",
    "print(f\"{tokens[0:70]}\\n\")\n",
    "reconstructed = tokenizer.convert_tokens_to_string(tokens)[0:73]\n",
    "print(reconstructed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5176b07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {\"accuracy\": (predictions == labels).mean()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fc78d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.2939870357513428, 'eval_accuracy': 0.1835985312117503, 'eval_runtime': 131.1589, 'eval_samples_per_second': 12.458, 'eval_steps_per_second': 0.785}\n"
     ]
    }
   ],
   "source": [
    "base_model_trainer = Trainer(\n",
    "    model= base_model,\n",
    "    args= TrainingArguments(\n",
    "    output_dir= \"./base_model_evaluation\",\n",
    "    per_device_eval_batch_size= 16,\n",
    "    do_train= False,\n",
    "    do_eval= True,\n",
    "),\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "base_model_metrics = base_model_trainer.evaluate()\n",
    "print(base_model_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a68d528b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>الخليجيين مبيستحموش واكتر ناس معفنا ونتنا ممكن...</td>\n",
       "      <td>Racism</td>\n",
       "      <td>Racism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>طريق زحمه قوي مش عارف هيفضل زحمه كده لحد امتي</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Racism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ده حتي فيه زنوج بيترياو علي بعض من كتر ما هما ...</td>\n",
       "      <td>Racism</td>\n",
       "      <td>Racism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>انا بزعل امي كتير ربنا يسامحني</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Racism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>انا نفسي في موبايل جديد بس مش معايا فلوس</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Racism</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text    label predicted_label\n",
       "0  الخليجيين مبيستحموش واكتر ناس معفنا ونتنا ممكن...   Racism          Racism\n",
       "1      طريق زحمه قوي مش عارف هيفضل زحمه كده لحد امتي  Neutral          Racism\n",
       "2  ده حتي فيه زنوج بيترياو علي بعض من كتر ما هما ...   Racism          Racism\n",
       "3                     انا بزعل امي كتير ربنا يسامحني  Neutral          Racism\n",
       "4           انا نفسي في موبايل جديد بس مش معايا فلوس  Neutral          Racism"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_test = dataset[\"test\"]\n",
    "pred_out = base_model_trainer.predict(tokenized_dataset[\"test\"])\n",
    "pred_ids = np.argmax(pred_out.predictions, axis=1)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"text\": raw_test[\"text\"],\n",
    "    \"label\": raw_test[\"label\"],\n",
    "    \"predicted_label\": [ id2label[i] for i in pred_ids ],\n",
    "})\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d52a229",
   "metadata": {},
   "source": [
    "## Performing Parameter-Efficient Fine-Tuning\n",
    "\n",
    "TODO: In the cells below, create a PEFT model from your loaded model, run a training loop, and save the PEFT model weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5775fadf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/peft/tuners/lora.py:475: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"c_attn\"],\n",
    "    lora_dropout=0.02,\n",
    "    task_type=\"SEQ_CLS\",\n",
    ")\n",
    "\n",
    "lora_model = get_peft_model(base_model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9053477e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 597,504 || all params: 125,037,312 || trainable%: 0.4778605605341228\n"
     ]
    }
   ],
   "source": [
    "lora_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be6ee105",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForSequenceClassification(\n",
       "  (base_model): LoraModel(\n",
       "    (model): GPT2ForSequenceClassification(\n",
       "      (transformer): GPT2Model(\n",
       "        (wte): Embedding(50257, 768)\n",
       "        (wpe): Embedding(1024, 768)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "        (h): ModuleList(\n",
       "          (0-11): 12 x GPT2Block(\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): GPT2Attention(\n",
       "              (c_attn): Linear(\n",
       "                in_features=768, out_features=2304, bias=True\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.02, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=768, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=2304, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (c_proj): Conv1D()\n",
       "              (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "              (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): GPT2MLP(\n",
       "              (c_fc): Conv1D()\n",
       "              (c_proj): Conv1D()\n",
       "              (act): NewGELUActivation()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (score): ModulesToSaveWrapper(\n",
       "        (original_module): Linear(in_features=768, out_features=5, bias=False)\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): Linear(in_features=768, out_features=5, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lora_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08a05d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original_module.weight: Parameter containing:\n",
      "tensor([[ 0.0031,  0.0055,  0.0034,  ...,  0.0051, -0.0155, -0.0438],\n",
      "        [ 0.0113,  0.0241, -0.0040,  ...,  0.0078, -0.0217, -0.0076],\n",
      "        [-0.0054, -0.0023, -0.0147,  ...,  0.0127,  0.0315, -0.0270],\n",
      "        [-0.0137,  0.0243, -0.0260,  ..., -0.0130,  0.0027,  0.0454],\n",
      "        [ 0.0168,  0.0175, -0.0219,  ..., -0.0233, -0.0272,  0.0018]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "modules_to_save.default.weight: Parameter containing:\n",
      "tensor([[ 0.0031,  0.0055,  0.0034,  ...,  0.0051, -0.0155, -0.0438],\n",
      "        [ 0.0113,  0.0241, -0.0040,  ...,  0.0078, -0.0217, -0.0076],\n",
      "        [-0.0054, -0.0023, -0.0147,  ...,  0.0127,  0.0315, -0.0270],\n",
      "        [-0.0137,  0.0243, -0.0260,  ..., -0.0130,  0.0027,  0.0454],\n",
      "        [ 0.0168,  0.0175, -0.0219,  ..., -0.0233, -0.0272,  0.0018]],\n",
      "       device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "head = lora_model.model.score\n",
    "for n, p in head.named_parameters():\n",
    "    print(f\"{n}: {p}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "894046c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OptimizerNames.ADAMW_TORCH\n"
     ]
    }
   ],
   "source": [
    "lora_trainer = Trainer(\n",
    "    model= lora_model,\n",
    "    args= TrainingArguments(\n",
    "    output_dir= \"lora-gpt2\",\n",
    "    per_device_train_batch_size= 2,\n",
    "    per_device_eval_batch_size= 2,\n",
    "    gradient_accumulation_steps= 2,\n",
    "    evaluation_strategy= \"epoch\",\n",
    "    save_strategy= \"epoch\",\n",
    "    num_train_epochs= 6,\n",
    "    learning_rate=5e-4,\n",
    "    warmup_steps=100,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end= True,\n",
    "),\n",
    "    train_dataset= tokenized_dataset[\"train\"],\n",
    "    eval_dataset= tokenized_dataset[\"test\"],\n",
    "    tokenizer= tokenizer,\n",
    "    data_collator= DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "    compute_metrics= compute_metrics,\n",
    ")\n",
    "\n",
    "print(lora_trainer.args.optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0316cc60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9804' max='9804' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9804/9804 2:33:27, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.310300</td>\n",
       "      <td>1.050025</td>\n",
       "      <td>0.591799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.933500</td>\n",
       "      <td>0.930773</td>\n",
       "      <td>0.671359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.775300</td>\n",
       "      <td>0.737174</td>\n",
       "      <td>0.753366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.659200</td>\n",
       "      <td>0.717998</td>\n",
       "      <td>0.771726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.596100</td>\n",
       "      <td>0.739166</td>\n",
       "      <td>0.793758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.524800</td>\n",
       "      <td>0.733569</td>\n",
       "      <td>0.805386</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=9804, training_loss=0.8413012927524998, metrics={'train_runtime': 9208.0135, 'train_samples_per_second': 4.258, 'train_steps_per_second': 1.065, 'total_flos': 2.063446359146496e+16, 'train_loss': 0.8413012927524998, 'epoch': 6.0})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lora_trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e8a663",
   "metadata": {},
   "source": [
    "###  ⚠️ IMPORTANT ⚠️\n",
    "\n",
    "Due to workspace storage constraints, you should not store the model weights in the same directory but rather use `/tmp` to avoid workspace crashes which are irrecoverable.\n",
    "Ensure you save it in /tmp always."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa7fe003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "lora_model.save_pretrained(\"temp/lora-gpt2/best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615b12c6",
   "metadata": {},
   "source": [
    "## Performing Inference with a PEFT Model\n",
    "\n",
    "TODO: In the cells below, load the saved PEFT model weights and evaluate the performance of the trained PEFT model. Be sure to compare the results to the results from prior to fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "863ec66e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PeftModelForSequenceClassification(\n",
       "  (base_model): LoraModel(\n",
       "    (model): GPT2ForSequenceClassification(\n",
       "      (transformer): GPT2Model(\n",
       "        (wte): Embedding(50257, 768)\n",
       "        (wpe): Embedding(1024, 768)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "        (h): ModuleList(\n",
       "          (0-11): 12 x GPT2Block(\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): GPT2Attention(\n",
       "              (c_attn): Linear(\n",
       "                in_features=768, out_features=2304, bias=True\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.02, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=768, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=2304, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (c_proj): Conv1D()\n",
       "              (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "              (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): GPT2MLP(\n",
       "              (c_fc): Conv1D()\n",
       "              (c_proj): Conv1D()\n",
       "              (act): NewGELUActivation()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (score): ModulesToSaveWrapper(\n",
       "        (original_module): Linear(in_features=768, out_features=5, bias=False)\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): Linear(in_features=768, out_features=5, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetuned_model = AutoPeftModelForSequenceClassification.from_pretrained(\n",
    "    \"temp/lora-gpt2/best\",\n",
    "    num_labels=num_labels,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    "    is_trainable=False\n",
    ")\n",
    "finetuned_model.config.pad_token_id = tokenizer.eos_token_id\n",
    "finetuned_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bc3a8147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7179978489875793, 'eval_accuracy': 0.7717258261933905, 'eval_runtime': 139.6509, 'eval_samples_per_second': 11.701, 'eval_steps_per_second': 0.738}\n"
     ]
    }
   ],
   "source": [
    "finetuned_model_trainer = Trainer(\n",
    "    model=finetuned_model,\n",
    "    args=TrainingArguments(\n",
    "        output_dir=\"./finetuned_model_evaluation\",\n",
    "        per_device_eval_batch_size=16,\n",
    "        do_train=False,\n",
    "        do_eval=True,\n",
    "    ),\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "finetuned_model_metrics = finetuned_model_trainer.evaluate()\n",
    "print(finetuned_model_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7d036b56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>الخليجيين مبيستحموش واكتر ناس معفنا ونتنا ممكن...</td>\n",
       "      <td>Racism</td>\n",
       "      <td>Racism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>طريق زحمه قوي مش عارف هيفضل زحمه كده لحد امتي</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ده حتي فيه زنوج بيترياو علي بعض من كتر ما هما ...</td>\n",
       "      <td>Racism</td>\n",
       "      <td>Racism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>انا بزعل امي كتير ربنا يسامحني</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>انا نفسي في موبايل جديد بس مش معايا فلوس</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text    label predicted_label\n",
       "0  الخليجيين مبيستحموش واكتر ناس معفنا ونتنا ممكن...   Racism          Racism\n",
       "1      طريق زحمه قوي مش عارف هيفضل زحمه كده لحد امتي  Neutral         Neutral\n",
       "2  ده حتي فيه زنوج بيترياو علي بعض من كتر ما هما ...   Racism          Racism\n",
       "3                     انا بزعل امي كتير ربنا يسامحني  Neutral         Neutral\n",
       "4           انا نفسي في موبايل جديد بس مش معايا فلوس  Neutral         Neutral"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetuned_pred_out = finetuned_model_trainer.predict(tokenized_dataset[\"test\"])\n",
    "finetuned_pred_ids = np.argmax(finetuned_pred_out.predictions, axis=1)\n",
    "\n",
    "df_finetuned = pd.DataFrame({\n",
    "    \"text\": raw_test[\"text\"],\n",
    "    \"label\": raw_test[\"label\"],\n",
    "    \"predicted_label\": [ id2label[i] for i in finetuned_pred_ids ],\n",
    "})\n",
    "\n",
    "df_finetuned.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bc96905a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrained gpt2 model accuracy:     0.1835985312117503\n",
      "Finetuned LoRA-gpt2 model accuracy: 0.7717258261933905\n"
     ]
    }
   ],
   "source": [
    "print(\"Pretrained gpt2 model accuracy:    \", base_model_metrics[\"eval_accuracy\"])\n",
    "print(\"Finetuned LoRA-gpt2 model accuracy:\", finetuned_model_metrics[\"eval_accuracy\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
